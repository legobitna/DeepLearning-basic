{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Vietnamese Poem Generation Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/legobitna/DeepLearning-basic/blob/main/Vietnamese_Poem_Generation_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBqErzFdt5AJ"
      },
      "source": [
        "![](https://i.imgur.com/1Bn8gwj.png)\n",
        "\n",
        "The data are two files in the data folder so please work on that!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjnCLZtut0Bm"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRZuT2Y7uDfn",
        "outputId": "4711a96e-6eaf-4ac5-898f-1c3802edd6a7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqFm3-zZuER1"
      },
      "source": [
        "data_file_1=\"/content/drive/MyDrive/FTMLE | 2020.09 | Kermadec/Week 10/10.1f_Vietnam_Poem_Generation_Exercise_(Lục_Bát)/crawled_data_from_www.thivien.net/a.txt\"\n",
        "data_file_2=\"/content/drive/MyDrive/FTMLE | 2020.09 | Kermadec/Week 10/10.1f_Vietnam_Poem_Generation_Exercise_(Lục_Bát)/crawled_data_from_www.thivien.net/b.txt\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M14Ss4c0uz7k"
      },
      "source": [
        "Here is a small poem from our data:\n",
        "\n",
        "```\n",
        "đường thu vàng cả thời gian \n",
        "gió se se lạnh vít làn thu sang \n",
        "đường quê nhạt nắng hanh vàng \n",
        "bao nhiêu kỷ niệm mơ màng trong ta \n",
        "gió thu môi ấm mặn mà \n",
        "ven hồ liễu rủ tóc nhoà điểm sương \n",
        "trời xanh chiều tím quê hương \n",
        "tìm về ký ức sắc hường ngẩn ngơ \n",
        "chông chênh cây trút lá rồi \n",
        "cành ươm mầm nhú khoảng trời nhấp nhô \n",
        "hương quê trên đường ngoại ô \n",
        "thu cùng ta đến bến bờ yêu thương \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7fxjMm2GFC4"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional,GlobalMaxPool1D,Dropout\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "import numpy as np "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lTdc1lIuQKw"
      },
      "source": [
        "# YOUR CODE TO GENERATE MORE VIETNAMESE POEMS (LỤC BÁT)\n",
        " \n",
        "tokenizer = Tokenizer(filters = '!\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "\n",
        "# it is stored in one single string\n",
        "# 1. 데이터를 읽어온다 \n",
        "data = open(data_file_1).read()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZidQUgBeuRIc"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "# 2. 데이터를 엔터기준으로 짜갠다 \r\n",
        "old_corpus = re.split('[.\\n]',data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uByjZkoKz4VJ",
        "outputId": "18f61e5c-464e-4675-a70f-ec34e86ac255"
      },
      "source": [
        "print(old_corpus[:10])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['đường thu vàng cả thời gian ', 'gió se se lạnh vít làn thu sang ', 'đường quê nhạt nắng hanh vàng ', 'bao nhiêu kỷ niệm mơ màng trong ta ', 'gió thu môi ấm mặn mà ', 'ven hồ liễu rủ tóc nhoà điểm sương ', 'trời xanh chiều tím quê hương ', 'tìm về ký ức sắc hường ngẩn ngơ ', 'chông chênh cây trút lá rồi ', 'cành ươm mầm nhú khoảng trời nhấp nhô ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMglorB0z7bx"
      },
      "source": [
        "# 3. 왠진 모르겠찌만 두문장씩 붙여준다 \r\n",
        "corpus = []\r\n",
        "tmp_cache = []\r\n",
        "for s in old_corpus:\r\n",
        "    stripped = s.strip()\r\n",
        "    if len(stripped):\r\n",
        "        if len(tmp_cache) in [0,1]:\r\n",
        "            tmp_cache.append(stripped)            \r\n",
        "            if len(tmp_cache)==2:\r\n",
        "                corpus.append(' . '.join(tmp_cache))\r\n",
        "                tmp_cache=[]\r\n",
        "if len(tmp_cache)==1:\r\n",
        "    corpus.append(tmp_cache[0])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbTDslGo0GlX",
        "outputId": "028432ed-4a67-4bfb-84b9-1132291fafda"
      },
      "source": [
        "corpus[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['đường thu vàng cả thời gian . gió se se lạnh vít làn thu sang',\n",
              " 'đường quê nhạt nắng hanh vàng . bao nhiêu kỷ niệm mơ màng trong ta',\n",
              " 'gió thu môi ấm mặn mà . ven hồ liễu rủ tóc nhoà điểm sương',\n",
              " 'trời xanh chiều tím quê hương . tìm về ký ức sắc hường ngẩn ngơ',\n",
              " 'chông chênh cây trút lá rồi . cành ươm mầm nhú khoảng trời nhấp nhô',\n",
              " 'hương quê trên đường ngoại ô . thu cùng ta đến bến bờ yêu thương',\n",
              " 'trăng là hoa của trời trong . sao kia tựa những cánh ong rụng rời',\n",
              " 'gió đàn hưu hắt người ơi . mây tơ con nhện rối bời không gian',\n",
              " 'trời cao mây gợn nắng lan . gió heo may thổi miên man bên rào',\n",
              " 'vài con bướm trắng lao xao . vàng bông hoa cúc cài vào vạt bay']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBSytNWh0Jew"
      },
      "source": [
        "#4. 문장에 인덱스를 부여한다 \r\n",
        "tokenizer.fit_on_texts(corpus)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P69568Cg0OK1"
      },
      "source": [
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm2HMlvo0REP",
        "outputId": "4d36c6fb-cd95-4d29-82f3-f0bd594de81e"
      },
      "source": [
        "print(total_words)\r\n",
        "len(corpus)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25141"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccT9m7Rj0Tej",
        "outputId": "7ba4ba12-b04e-4080-8d20-aa4a9cdd9d60"
      },
      "source": [
        "#what happen in the first loop\r\n",
        "# 5. 인덱스넘버를 각각 단어에 부여하는데 없는단어이면 넘어가버림 \r\n",
        "print(corpus[2])\r\n",
        "token_list = tokenizer.texts_to_sequences([corpus[2]])[0]\r\n",
        "token_list"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gió thu môi ấm mặn mà . ven hồ liễu rủ tóc nhoà điểm sương\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[26, 113, 249, 290, 570, 38, 1, 1677, 376, 971, 1073, 158, 2020, 1007, 129]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZHh_gtH0h-3",
        "outputId": "0f57a40e-f99f-4e87-b9c8-93a10ea48bb9"
      },
      "source": [
        "\r\n",
        "input_sequences=[]\r\n",
        "for i in range(1, len(token_list)):\r\n",
        "    n_gram_sequence = token_list[:i+1]\r\n",
        "    input_sequences.append(n_gram_sequence)\r\n",
        "input_sequences"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[26, 113],\n",
              " [26, 113, 249],\n",
              " [26, 113, 249, 290],\n",
              " [26, 113, 249, 290, 570],\n",
              " [26, 113, 249, 290, 570, 38],\n",
              " [26, 113, 249, 290, 570, 38, 1],\n",
              " [26, 113, 249, 290, 570, 38, 1, 1677],\n",
              " [26, 113, 249, 290, 570, 38, 1, 1677, 376],\n",
              " [26, 113, 249, 290, 570, 38, 1, 1677, 376, 971],\n",
              " [26, 113, 249, 290, 570, 38, 1, 1677, 376, 971, 1073],\n",
              " [26, 113, 249, 290, 570, 38, 1, 1677, 376, 971, 1073, 158],\n",
              " [26, 113, 249, 290, 570, 38, 1, 1677, 376, 971, 1073, 158, 2020],\n",
              " [26, 113, 249, 290, 570, 38, 1, 1677, 376, 971, 1073, 158, 2020, 1007],\n",
              " [26, 113, 249, 290, 570, 38, 1, 1677, 376, 971, 1073, 158, 2020, 1007, 129]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5wvZcR00pXR"
      },
      "source": [
        "# 5. 전체데이터에 인덱스 부여 \r\n",
        "input_sequences = []\r\n",
        "for line in corpus:\r\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\r\n",
        "    # we are generating n-gram from the token list above\r\n",
        "    for i in range(1, len(token_list)):\r\n",
        "        n_gram_sequence = token_list[:i+1]\r\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZcT5kTh0sxc",
        "outputId": "71126622-5357-4fbf-b053-1cb0368bf703"
      },
      "source": [
        "input_sequences[:20]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 113],\n",
              " [34, 113, 66],\n",
              " [34, 113, 66, 148],\n",
              " [34, 113, 66, 148, 109],\n",
              " [34, 113, 66, 148, 109, 141],\n",
              " [34, 113, 66, 148, 109, 141, 1],\n",
              " [34, 113, 66, 148, 109, 141, 1, 26],\n",
              " [34, 113, 66, 148, 109, 141, 1, 26, 1111],\n",
              " [34, 113, 66, 148, 109, 141, 1, 26, 1111, 1111],\n",
              " [34, 113, 66, 148, 109, 141, 1, 26, 1111, 1111, 267],\n",
              " [34, 113, 66, 148, 109, 141, 1, 26, 1111, 1111, 267, 1806],\n",
              " [34, 113, 66, 148, 109, 141, 1, 26, 1111, 1111, 267, 1806, 961],\n",
              " [34, 113, 66, 148, 109, 141, 1, 26, 1111, 1111, 267, 1806, 961, 113],\n",
              " [34, 113, 66, 148, 109, 141, 1, 26, 1111, 1111, 267, 1806, 961, 113, 136],\n",
              " [34, 48],\n",
              " [34, 48, 633],\n",
              " [34, 48, 633, 57],\n",
              " [34, 48, 633, 57, 1120],\n",
              " [34, 48, 633, 57, 1120, 66],\n",
              " [34, 48, 633, 57, 1120, 66, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zv0oawo0ycl",
        "outputId": "66edf5b9-4226-487d-a84f-e995c115d3a6"
      },
      "source": [
        "# 6. 가장긴게 23임 \r\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\r\n",
        "max_sequence_len"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "jgMj74XX1C16",
        "outputId": "401fd593-e963-41ab-f93d-76a2270f548e"
      },
      "source": [
        "import pandas as pd\r\n",
        "pd.Series([len(x) for x in input_sequences]).plot(kind='hist')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7feaca5d6278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD4CAYAAAAtrdtxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWYUlEQVR4nO3dcbCddX3n8fdHIgWtSJDbLEOwwTajpVYRrpCOtqsyhoCtoTstxWmXDMMQZ4g7OtuZbXQ6G1frDP5RWdmxjFSyJK6KSItkKzSN0Wl3/0C5KAsCMrlFGBKBpAaJiiuLfveP87tyDPfenDzhnHtv7vs1c+b8nu/ze57zO3fO3M88z/M7z0lVIUlSFy+a6wFIkhYuQ0SS1JkhIknqzBCRJHVmiEiSOlsy1wMYtZNPPrlWrFgx18OQpAXjrrvu+teqGptu3aILkRUrVjAxMTHXw5CkBSPJIzOt83SWJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKmzRfeN9SOxYuOX5uR1H77qHXPyupJ0KB6JSJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0NLUSSvDrJ3X2PA0nel+SkJDuS7GrPS1v/JLkmyWSSe5Kc1bevda3/riTr+upnJ7m3bXNNkgzr/UiSnm9oIVJVD1bVmVV1JnA28DRwC7AR2FlVK4GdbRngAmBle6wHrgVIchKwCTgXOAfYNBU8rc8VfdutGdb7kSQ936hOZ50H/EtVPQKsBba0+hbgotZeC2ytnjuAE5OcApwP7Kiq/VX1JLADWNPWnVBVd1RVAVv79iVJGoFRhcglwOdae1lVPdbajwPLWvtU4NG+bXa32mz13dPUJUkjMvQQSXIs8E7gCweva0cQNYIxrE8ykWRi3759w345SVo0RnEkcgHwjap6oi0/0U5F0Z73tvoe4LS+7Za32mz15dPUn6eqrquq8aoaHxsbO8K3I0maMooQeRfPncoC2AZMzbBaB9zaV7+0zdJaBTzVTnttB1YnWdouqK8Gtrd1B5KsarOyLu3blyRpBIb6y4ZJXgq8HXh3X/kq4KYklwOPABe3+m3AhcAkvZlclwFU1f4kHwbubP0+VFX7W/tK4AbgeOD29pAkjchQQ6SqfgS84qDa9+jN1jq4bwEbZtjPZmDzNPUJ4LUvyGAlSYfNb6xLkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTOhhoiSU5McnOSbyd5IMlvJzkpyY4ku9rz0tY3Sa5JMpnkniRn9e1nXeu/K8m6vvrZSe5t21yTJMN8P5KkXzTsI5GPA/9QVa8BXg88AGwEdlbVSmBnWwa4AFjZHuuBawGSnARsAs4FzgE2TQVP63NF33Zrhvx+JEl9hhYiSV4O/C5wPUBVPVNV3wfWAltaty3ARa29FthaPXcAJyY5BTgf2FFV+6vqSWAHsKatO6Gq7qiqArb27UuSNALDPBI5HdgH/Pck30zyqSQvBZZV1WOtz+PAstY+FXi0b/vdrTZbffc09edJsj7JRJKJffv2HeHbkiRNGWaILAHOAq6tqjcAP+K5U1cAtCOIGuIYpl7nuqoar6rxsbGxYb+cJC0awwyR3cDuqvpaW76ZXqg80U5F0Z73tvV7gNP6tl/earPVl09TlySNyNBCpKoeBx5N8upWOg+4H9gGTM2wWgfc2trbgEvbLK1VwFPttNd2YHWSpe2C+mpge1t3IMmqNivr0r59SZJGYMmQ9/8fgM8kORZ4CLiMXnDdlORy4BHg4tb3NuBCYBJ4uvWlqvYn+TBwZ+v3oara39pXAjcAxwO3t4ckaUSGGiJVdTcwPs2q86bpW8CGGfazGdg8TX0CeO0RDlOS1JHfWJckdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6G2qIJHk4yb1J7k4y0WonJdmRZFd7XtrqSXJNkskk9yQ5q28/61r/XUnW9dXPbvufbNtmmO9HkvSLRnEk8taqOrOqpn5rfSOws6pWAjvbMsAFwMr2WA9cC73QATYB5wLnAJumgqf1uaJvuzXDfzuSpClzcTprLbCltbcAF/XVt1bPHcCJSU4Bzgd2VNX+qnoS2AGsaetOqKo7qqqArX37kiSNwJIh77+Af0xSwCer6jpgWVU91tY/Dixr7VOBR/u23d1qs9V3T1M/6qzY+KW5HoKOYg9f9Y65HoIWsGGHyJurak+SXwF2JPl2/8qqqhYwQ5VkPb1TZLzyla8c9stJ0qIx1NNZVbWnPe8FbqF3TeOJdiqK9ry3dd8DnNa3+fJWm62+fJr6dOO4rqrGq2p8bGzsSN+WJKkZWogkeWmSl021gdXAt4BtwNQMq3XAra29Dbi0zdJaBTzVTnttB1YnWdouqK8Gtrd1B5KsarOyLu3blyRpBIZ5OmsZcEubdbsE+GxV/UOSO4GbklwOPAJc3PrfBlwITAJPA5cBVNX+JB8G7mz9PlRV+1v7SuAG4Hjg9vaQJI3I0EKkqh4CXj9N/XvAedPUC9gww742A5unqU8Arz3iwUqSOhnodFaS3xr2QCRJC8+g10T+OsnXk1yZ5OVDHZEkacEYKESq6neAP6E3S+quJJ9N8vahjkySNO8NPDurqnYBfwH8OfBvgWuSfDvJvxvW4CRJ89ug10Rel+Rq4AHgbcDvV9VvtPbVQxyfJGkeG3R21n8DPgV8oKp+PFWsqu8m+YuhjEySNO8NGiLvAH5cVT8FSPIi4LiqerqqPj200UmS5rVBr4l8md4X+qa8pNUkSYvYoCFyXFX9cGqhtV8ynCFJkhaKQUPkRwf90uDZwI9n6S9JWgQGvSbyPuALSb4LBPg3wB8PbVSSpAVhoBCpqjuTvAZ4dSs9WFX/b3jDkiQtBIdzA8Y3AivaNmcloaq2DmVUkqQFYaAQSfJp4NeAu4GftvLU75pLkhapQY9ExoEz2u3aJUkCBp+d9S16F9MlSfq5QY9ETgbuT/J14CdTxap651BGJUlaEAYNkQ8OcxCSpIVp0Cm+/5TkV4GVVfXlJC8Bjhnu0CRJ892gt4K/ArgZ+GQrnQp8ccBtj0nyzSR/35ZPT/K1JJNJPp/k2Fb/pbY82dav6NvH+1v9wSTn99XXtNpkko2DjEeS9MIZ9ML6BuBNwAH4+Q9U/cqA276X3u+QTPkocHVV/TrwJHB5q18OPNnqV7d+JDkDuAT4TWANvZ/qPSbJMcAngAuAM4B3tb6SpBEZNER+UlXPTC0kWULveyKzSrKc3m3kP9WWQ++HrG5uXbYAF7X22rZMW39e678WuLGqflJV3wEmgXPaY7KqHmpju7H1lSSNyKAh8k9JPgAc335b/QvA/xxgu/8K/CfgZ235FcD3q+rZtryb3qkx2vOjAG39U63/z+sHbTNT/XmSrE8ykWRi3759AwxbkjSIQUNkI7APuBd4N3Abvd9bn1GS3wP2VtVdRzTCF0BVXVdV41U1PjY2NtfDkaSjxqCzs34G/E17DOpNwDuTXAgcB5wAfBw4McmSdrSxHNjT+u8BTgN2t9NlLwe+11ef0r/NTHVJ0ggMOjvrO0keOvgx2zZV9f6qWl5VK+hdGP9KVf0J8FXgD1u3dcCtrb2tLdPWf6XdZmUbcEmbvXU6sBL4OnAnsLLN9jq2vca2Ad+3JOkFcDj3zppyHPBHwEkdX/PPgRuT/CXwTeD6Vr8e+HSSSWA/vVCgqu5LchNwP/AssKHvt97fA2yn952VzVV1X8cxSZI6SNd7Kia5q6rOfoHHM3Tj4+M1MTHRadsVG7/0Ao9GmnsPX/WOuR6C5rn2/358unWD3gr+rL7FF9E7Mjmc3yKRJB2FBg2Cv+prPws8DFz8go9GkrSgDDo7663DHogkaeEZ9HTWf5xtfVV97IUZjiRpITmc2Vlv5LkptL9Pb5rtrmEMSpK0MAwaIsuBs6rqBwBJPgh8qar+dFgDkyTNf4Pe9mQZ8Ezf8jOtJklaxAY9EtkKfD3JLW35Ip67464kaZEadHbWR5LcDvxOK11WVd8c3rAkSQvBoKezAF4CHKiqj9O7SeLpQxqTJGmBGPQGjJvo3fPq/a30YuB/DGtQkqSFYdAjkT8A3gn8CKCqvgu8bFiDkiQtDIOGyDPttuwFkOSlwxuSJGmhGDREbkrySXo/KHUF8GUO7weqJElHoUPOzkoS4PPAa4ADwKuB/1xVO4Y8NknSPHfIEKmqSnJbVf0WYHBIkn5u0NNZ30jyxqGORJK04Az6jfVzgT9N8jC9GVqhd5DyumENTJI0/816JJLkla15PvAq4G307uD7e+15tm2PS/L1JP8nyX1J/kurn57ka0kmk3w+ybGt/kttebKtX9G3r/e3+oNJzu+rr2m1ySQbD//tS5KOxKFOZ30RoKoeAT5WVY/0Pw6x7U+At1XV64EzgTVJVgEfBa6uql8HngQub/0vB55s9atbP5KcAVwC/CawBvjrJMckOQb4BHABcAbwrtZXkjQihwqR9LVfdTg7rp4ftsUXt0fRO5q5udW30LuZI8Banrup483AeW1m2Frgxqr6SVV9B5gEzmmPyap6qKqeAW5sfSVJI3KoEKkZ2gNpRwx3A3vpzez6F+D7VfVs67IbOLW1TwUeBWjrnwJe0V8/aJuZ6tONY32SiSQT+/btO9y3IUmawaFC5PVJDiT5AfC61j6Q5AdJDhxq51X106o6k96PWp1D77smI1dV11XVeFWNj42NzcUQJOmoNOvsrKo65oV4kar6fpKvAr9N71vvS9rRxnJgT+u2BziN3h2ClwAvB77XV5/Sv81MdUnSCBzOreAPS5KxJCe29vHA24EHgK8Cf9i6rQNube1tbZm2/ivtfl3bgEva7K3TgZX0ft/9TmBlm+11LL2L71O/AS9JGoFBvyfSxSnAljaL6kXATVX190nuB25M8pfAN4HrW//rgU8nmQT20wsFquq+JDcB9wPPAhuq6qcASd4DbAeOATZX1X1DfD+SpIMMLUSq6h7gDdPUH6J3feTg+v8F/miGfX0E+Mg09duA2454sJKkToZ2OkuSdPQzRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1NsxvrEtaAFZs/NKcvfbDV71jzl5bLwyPRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTOhhYiSU5L8tUk9ye5L8l7W/2kJDuS7GrPS1s9Sa5JMpnkniRn9e1rXeu/K8m6vvrZSe5t21yTJMN6P5Kk5xvmkcizwJ9V1RnAKmBDkjOAjcDOqloJ7GzLABcAK9tjPXAt9EIH2AScC5wDbJoKntbnir7t1gzx/UiSDjK0EKmqx6rqG639A+AB4FRgLbClddsCXNTaa4Gt1XMHcGKSU4DzgR1Vtb+qngR2AGvauhOq6o6qKmBr374kSSMwkmsiSVYAbwC+BiyrqsfaqseBZa19KvBo32a7W222+u5p6tO9/vokE0km9u3bd0TvRZL0nKGHSJJfBv4WeF9VHehf144gathjqKrrqmq8qsbHxsaG/XKStGgMNUSSvJhegHymqv6ulZ9op6Joz3tbfQ9wWt/my1tttvryaeqSpBEZ5uysANcDD1TVx/pWbQOmZlitA27tq1/aZmmtAp5qp722A6uTLG0X1FcD29u6A0lWtde6tG9fkqQRGOYvG74J+PfAvUnubrUPAFcBNyW5HHgEuLituw24EJgEngYuA6iq/Uk+DNzZ+n2oqva39pXADcDxwO3tIUkakaGFSFX9b2Cm722cN03/AjbMsK/NwOZp6hPAa49gmJKkI+A31iVJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTOhhYiSTYn2ZvkW321k5LsSLKrPS9t9SS5JslkknuSnNW3zbrWf1eSdX31s5Pc27a5JslMP8UrSRqSYR6J3ACsOai2EdhZVSuBnW0Z4AJgZXusB66FXugAm4BzgXOATVPB0/pc0bfdwa8lSRqyoYVIVf0zsP+g8lpgS2tvAS7qq2+tnjuAE5OcApwP7Kiq/VX1JLADWNPWnVBVd1RVAVv79iVJGpFRXxNZVlWPtfbjwLLWPhV4tK/f7labrb57mvq0kqxPMpFkYt++fUf2DiRJPzdnF9bbEUSN6LWuq6rxqhofGxsbxUtK0qIw6hB5op2Koj3vbfU9wGl9/Za32mz15dPUJUkjNOoQ2QZMzbBaB9zaV7+0zdJaBTzVTnttB1YnWdouqK8Gtrd1B5KsarOyLu3blyRpRJYMa8dJPge8BTg5yW56s6yuAm5KcjnwCHBx634bcCEwCTwNXAZQVfuTfBi4s/X7UFVNXay/kt4MsOOB29tDkjRCQwuRqnrXDKvOm6ZvARtm2M9mYPM09QngtUcyRknSkfEb65KkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqbMFHyJJ1iR5MMlkko1zPR5JWkwWdIgkOQb4BHABcAbwriRnzO2oJGnxWNAhApwDTFbVQ1X1DHAjsHaOxyRJi8aSuR7AEToVeLRveTdw7sGdkqwH1rfFHyZ5cARjm2snA/8614OY5/wbzW7of598dJh7H4nF8hn61ZlWLPQQGUhVXQdcN9fjGKUkE1U1PtfjmM/8G83Ov8+h+Tda+Kez9gCn9S0vbzVJ0ggs9BC5E1iZ5PQkxwKXANvmeEyStGgs6NNZVfVskvcA24FjgM1Vdd8cD2u+WFSn7zrybzQ7/z6Htuj/RqmquR6DJGmBWuinsyRJc8gQkSR1ZogchZI8nOTeJHcnmZjr8cwHSTYn2ZvkW321k5LsSLKrPS+dyzHOpRn+Ph9Msqd9ju5OcuFcjnEuJTktyVeT3J/kviTvbfVF/xkyRI5eb62qMxf7HPY+NwBrDqptBHZW1UpgZ1terG7g+X8fgKvb5+jMqrptxGOaT54F/qyqzgBWARvaLZYW/WfIENGiUFX/DOw/qLwW2NLaW4CLRjqoeWSGv4+aqnqsqr7R2j8AHqB3x4xF/xkyRI5OBfxjkrvaLV80vWVV9VhrPw4sm8vBzFPvSXJPO9216E7VTCfJCuANwNfwM2SIHKXeXFVn0bu78YYkvzvXA5rvqjfX3fnuv+ha4NeAM4HHgL+a2+HMvSS/DPwt8L6qOtC/brF+hgyRo1BV7WnPe4Fb6N3tWM/3RJJTANrz3jkez7xSVU9U1U+r6mfA37DIP0dJXkwvQD5TVX/Xyov+M2SIHGWSvDTJy6bawGrgW7NvtWhtA9a19jrg1jkcy7wz9c+x+QMW8ecoSYDrgQeq6mN9qxb9Z8hvrB9lkryK3tEH9G5r89mq+sgcDmleSPI54C30bt39BLAJ+CJwE/BK4BHg4qpalBeXZ/j7vIXeqawCHgbe3Xf+f1FJ8mbgfwH3Aj9r5Q/Quy6yqD9DhogkqTNPZ0mSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknq7P8D9ELTd053drgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eorSVaiy1Lle"
      },
      "source": [
        "# , 짧은 문장은 패딩도 앞에 넣어줌 \r\n",
        "\r\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, truncating='pre', padding='pre'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9FCSqf41dRt"
      },
      "source": [
        "# 문장과 문장끝에 단어 분리해서 라벨만들기 \r\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "585INyTG1lcR"
      },
      "source": [
        "# 라벨로 띄어둔 단어를 뭔가 특별하게 인코딩 \r\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqrBsr221txU",
        "outputId": "5f5f3ee7-1974-447c-d442-51bda8867cc5"
      },
      "source": [
        "# 아까 맥스렝쓰를 16으로 했으니까 xs 는 15가 맞음 나머지 1은 라벨로 떨어져나감 \r\n",
        "xs.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351964, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URa_O4ag3hdy"
      },
      "source": [
        "# !wget --no-check-certificate \\\r\n",
        "#     https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\r\n",
        "#     -O /content/glove.6B.100d.txt"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Tn_-gc3rje"
      },
      "source": [
        "# 단어의 특성을 나타내주는 glove 다운 및 워드 임베딩 준비 \r\n",
        "# import numpy as np\r\n",
        "# from pathlib import Path\r\n",
        "# path_to_glove_file = Path('glove.6B.100d.txt')\r\n",
        "\r\n",
        "\r\n",
        "# embeddings_index = {}\r\n",
        "# with open(path_to_glove_file) as f:\r\n",
        "#     for line in f:\r\n",
        "#         word, coefs = line.split(maxsplit=1)\r\n",
        "#         coefs = np.fromstring(coefs, \"f\", sep=\" \")\r\n",
        "#         embeddings_index[word] = coefs\r\n",
        "\r\n",
        "# print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak3ULtyo1xER"
      },
      "source": [
        "#워드 임베딩 레이어 준비 \r\n",
        "# embedding_layer = tf.keras.layers.Embedding(\r\n",
        "#     total_words,\r\n",
        "#     100,\r\n",
        "#     embeddings_initializer=tf.keras.initializers.Constant(embeddings_index),\r\n",
        "#     trainable=True, # experiment with this\r\n",
        "#     input_length=max_sequence_len-1\r\n",
        "# )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce8XyXrO2RQw",
        "outputId": "ffbe51a4-2683-4802-a377-61040a0a69cc"
      },
      "source": [
        "# 모델 만들기 \r\n",
        "# 이거는 glove 추가시에 쓰던 모델 근데 이거는 그거 필요 없는듯 \r\n",
        "# model = Sequential()\r\n",
        "\r\n",
        "# # input_length we need to minus 1 here because we take one out to become the label\r\n",
        "# model.add(embedding_layer)\r\n",
        "# # model.add(Bidirectional(LSTM(128,return_sequences=True)))\r\n",
        "# model.add(LSTM(128))\r\n",
        "# # model.add(GlobalMaxPool1D())\r\n",
        "# model.add(Dropout(0.2))\r\n",
        "# model.add(Dense(total_words, activation='softmax'))\r\n",
        "# adam = Adam(lr=0.01)\r\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# input_length we need to minus 1 here because we take one out to become the label\r\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\r\n",
        "model.add(Bidirectional(LSTM(150)))\r\n",
        "model.add(Dense(total_words, activation='softmax'))\r\n",
        "adam = Adam(lr=0.01)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\r\n",
        "history = model.fit(xs, ys, epochs=2, verbose=1)\r\n",
        "#print model.summary()\r\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " 2662/10999 [======>.......................] - ETA: 12:19 - loss: 7.2937 - accuracy: 0.0733"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-eGBI0Q4Ceb"
      },
      "source": [
        "# 모델 훈련 \r\n",
        "# history = model.fit(xs, ys, epochs=100, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZlLC_Ep4TWM"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "def plot_graphs(history, string):\r\n",
        "    plt.plot(history.history[string])\r\n",
        "    plt.xlabel(\"Epochs\")\r\n",
        "    plt.ylabel(string)\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQTCQtja4UKS"
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFCERhwO4bNM"
      },
      "source": [
        "# 이제 한번 ㄴ테스트 어떤 문장이 만들어 지는지 \r\n",
        "seed_text = \"ao thu lạnh lẽo\"\r\n",
        "next_words = 52\r\n",
        "  \r\n",
        "for _ in range(next_words):\r\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\r\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\r\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\r\n",
        "  \r\n",
        "\toutput_word = \"\"\r\n",
        "\tfor word, index in tokenizer.word_index.items():\r\n",
        "\t\tif index == predicted:\r\n",
        "\t\t\toutput_word = word\r\n",
        "\t\t\tbreak\r\n",
        "\tseed_text += \" \" + output_word\r\n",
        "print(seed_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBOcdeHh_NgD"
      },
      "source": [
        "seed_list=seed_text.split()\r\n",
        "\r\n",
        "while seed_list:\r\n",
        "  for i in range(6):\r\n",
        "    if seed_list:\r\n",
        "      word = seed_list[0]\r\n",
        "      seed_list = seed_list[1:]\r\n",
        "      print(word,end=\" \")\r\n",
        "  print()\r\n",
        "  for i in range(8):\r\n",
        "    if seed_list:\r\n",
        "      word = seed_list[0]\r\n",
        "      seed_list = seed_list[1:]\r\n",
        "      print(word,end=\" \")\r\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}