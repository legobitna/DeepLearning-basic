{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 7.4a_FTMLE_Introduction_to_TensorFlow Lecture_Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/legobitna/DeepLearning-basic/blob/main/7_4a_FTMLE_Introduction_to_TensorFlow_Lecture_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfWvQ4tA9ZOe"
      },
      "source": [
        "# Introduction to TensorFlow\n",
        "\n",
        "![](https://camo.githubusercontent.com/0905c7d634421f8aa4ab3ddf19a582572df568e1/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f74665f6c6f676f5f736f6369616c2e706e67)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjNuN2iy-Cbo"
      },
      "source": [
        "## Tensorflow High level API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs4YWfsi_DmO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm3h3lcr8-4O"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vSdH3l858SO"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a-e-BNDKSEb"
      },
      "source": [
        "*Load and prepare MNIST dataset:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pArAx02s-q3C"
      },
      "source": [
        "# Load the MNIST digit dataset\n",
        "mnist = tf.keras.datasets.mnist                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOHYN2O5R5Jf"
      },
      "source": [
        "# Plot some train samples\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Some some random images and their labels\n",
        "fig, ax = plt.subplots(2, 6, figsize = (12,8))\n",
        "for i in range(2):\n",
        "  for j in range(6):\n",
        "    index = np.random.randint(0, len(X_train)) \n",
        "    ax[i,j].imshow(X_train[index], cmap='Greys') # you can use cmap='gray' for another display color map\n",
        "    ax[i,j].set_title(f'Label: {y_train[index]}')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rTC0mUO935J"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmZHa-QRKaQ9"
      },
      "source": [
        "*Build the tf.keras.Sequential model by stacking layers:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb9JRMd7sw8m"
      },
      "source": [
        "# Create a Deep Neural Network\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='Adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZJg-99uMxCj"
      },
      "source": [
        "# View the structure of the network\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fLc7mt_KoIF"
      },
      "source": [
        "*Build the tf.keras.Sequential model by stacking layers. Choose an optimizer and loss function for training:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYGF6BpgKkYu"
      },
      "source": [
        "# Train the model with Train data\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dChx-FilIxey"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbenRKQkKmse"
      },
      "source": [
        "# Evaluate the model with Test data\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLGPlRG6hK1Y"
      },
      "source": [
        "# Visualize model history\n",
        "def plot_history(history, key='loss'):\n",
        "    plt.figure(figsize=(12,8))\n",
        "\n",
        "    val = plt.plot(history.epoch, history.history['val_'+key],'--', label=key.title() +' Val')\n",
        "    plt.plot(history.epoch, history.history[key], color=val[0].get_color(), label=key.title() + ' Train')\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(key.replace('_',' ').title())\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlim([0,max(history.epoch)])\n",
        "\n",
        "plot_history(history, key='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPFZ_wC-LipN"
      },
      "source": [
        "**Cool, how can I export this model. I have to deploy it on a Flask app for my weekly/final project!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNQN2Bv-Nn4K"
      },
      "source": [
        "*I will show you how to Save Checkpoints during training. You can use a trained model without having to retrain it, or pick-up training where you left off—in case the training process was interrupted. The [tf.keras.callbacks.ModelCheckpoint](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/ModelCheckpoint) callback allows to continually save the model both during and at the end of training.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tHyLo_GOBEq"
      },
      "source": [
        "*Create a tf.keras.callbacks.ModelCheckpoint callback that saves weights only during training:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spz9ZpVZMpXj"
      },
      "source": [
        "checkpoint_path = \"my_model.h5\"\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "# by default it saves the weights every epoch\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=False,\n",
        "                                                 save_best_only=True,\n",
        "                                                 verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1yXK4XhOGZC"
      },
      "source": [
        "# Train the model with the new callback\n",
        "model = create_model()\n",
        "history = model.fit(X_train, \n",
        "                    y_train,  \n",
        "                    epochs=10,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[cp_callback])  # Pass callback to training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NODAI0iPrVn"
      },
      "source": [
        "*Now rebuild a fresh, untrained model, and evaluate it on the test set. An untrained model will perform at chance levels (~10% accuracy):*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjVBRCRZOyYi"
      },
      "source": [
        "# Create a basic model instance\n",
        "new_model = create_model()\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = new_model.evaluate(X_test, y_test)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMVHkIBbQXSz"
      },
      "source": [
        "*Then load the weights from the checkpoint and re-evaluate*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PccKbhCP-JV"
      },
      "source": [
        "# Loads the weights\n",
        "new_model.load_weights(checkpoint_path)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = new_model.evaluate(X_test, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wecs8YxOVED"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG6a7vgH2wrU"
      },
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model_2 = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model_2.summary()\n",
        "# .compile 이게 없으면 정확도 10프로 밖에안나옴 기존에 트레인된 모델 my_model.h5를 썻음에도 불구하고 \n",
        "new_model_2.compile(optimizer='Adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Re-evaluate the model\n",
        "loss, acc = new_model_2.evaluate(X_test, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4PtAMYG2_vU"
      },
      "source": [
        "new_model_2.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKUGWxvu3EVu"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QoT465NTf6z"
      },
      "source": [
        "**That's only the model's weights. How can I save the entire model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlLRyKLETsgl"
      },
      "source": [
        "*The model and optimizer can be saved to a file that contains both their state (weights and variables) and the model configuration. This allows you to export a model so it can be used without access to the original Python code. Since the optimizer-state is recovered, you can resume training from exactly where you left off.*\n",
        "\n",
        "*Saving a fully-functional model is very useful—you can load them in TensorFlow.js ([HDF5](https://js.tensorflow.org/tutorials/import-keras.html), [Saved Model](https://js.tensorflow.org/tutorials/import-saved-model.html)) and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite ([HDF5](https://www.tensorflow.org/lite/convert/python_api#exporting_a_tfkeras_file_), [Saved Model](https://www.tensorflow.org/lite/convert/python_api#exporting_a_savedmodel_))*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClNBAP40QeEY"
      },
      "source": [
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5)\n",
        "\n",
        "# Save the entire model to a HDF5 file\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1pIgea0UVU4"
      },
      "source": [
        "*Now, recreate the model from that file:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XNPOHDRUKEj"
      },
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "treAp1mLUllP"
      },
      "source": [
        "*Check its accuracy:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkhQNAd3UaLD"
      },
      "source": [
        "loss, acc = new_model.evaluate(X_test, y_test)\n",
        "#print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyyIfE49GPa2"
      },
      "source": [
        "### Practice (Time to shine!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye8KDbpWGSgP"
      },
      "source": [
        "# Load data\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# normalize the images\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADtNqOTWT5xO"
      },
      "source": [
        "# Plot some train samples\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Some some random images and their labels\n",
        "fig, ax = plt.subplots(2, 6, figsize = (12,8))\n",
        "for i in range(2):\n",
        "  for j in range(6):\n",
        "    index = np.random.randint(0, len(X_train)) \n",
        "    ax[i,j].imshow(X_train[index], cmap='Greys') # you can use cmap='gray' for another display color map\n",
        "    ax[i,j].set_title(f'Label: {y_train[index]}')\n",
        "\n",
        "plt.show()\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMgOlRy5Uic0"
      },
      "source": [
        "# can you follow the above steps and build a model to get evaluation accuracy up to 90% for fashion MNIST for validation?\n",
        "# Create a new model instance\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "          tf.keras.layers.Dense(128, activation='relu'),\n",
        "          tf.keras.layers.Dense(64, activation='relu'),\n",
        "          tf.keras.layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "\n",
        "\n",
        "    model.compile(optimizer='Adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_pYWjmIW9Qb"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=40, validation_data=(X_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajdo96kgWx9H"
      },
      "source": [
        "# evaluate your model with X_test and y_test\n",
        "# Re-evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRwCP5DKXgCW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjbSKTc5V_pf"
      },
      "source": [
        "## Transfer Learning and Preprocessing with Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e2ZpKPDo-m-"
      },
      "source": [
        "###Dealing with image paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2MGAUVTUnv_"
      },
      "source": [
        "import pathlib\n",
        "data_root_orig = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "                                         fname='flower_photos', untar=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIuIshGnkVNu"
      },
      "source": [
        "We use Python’s pathlib module pretty much anytime you need to work with files in Python since we do not need to deal with different syntax for paths in different Operating Systems (like Windows, Linux and MacOS). For example, in Windows, we have \"C:\\Users\\Tom\\Downloads\" but in Linux, we have \"\\/Users\\/Tom\\/Downloads\" so hard-coding \"/\" or \"\\\\\" won't work for both of them. So pathlib is here to save our world!\n",
        "\n",
        "The pathlib module replaces many of these filesystem-related os utilities with methods on the Path object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag_5kY-oXRkz"
      },
      "source": [
        "data_root = pathlib.Path(data_root_orig)\n",
        "print(data_root)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nPag-huXJoN"
      },
      "source": [
        "*After downloading 218MB, you should now have a copy of the flower photos available:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD85ilz4XEYa"
      },
      "source": [
        "for item in data_root.iterdir():\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTl5BZCrlfZ7"
      },
      "source": [
        "The pathlib.Path modules aren’t the only filepath/filesystem-related utilities in the Python standard library. The **glob** module is another handy path-related module.\n",
        "\n",
        "We can use the glob.glob function for finding files that match a certain pattern:\n",
        "\n",
        "```\n",
        "An asterisk (*) matches zero or more characters in a segment of a name. For example, dir/*\n",
        "\n",
        "dir/file.txt\n",
        "dir/file1.jpg\n",
        "dir/random.txt\n",
        "dir/subdir\n",
        "```\n",
        "\n",
        "```\n",
        "To list files in a subdirectory, you must include the subdirectory in the pattern, like ('dir/*/*'):\n",
        "dir/subdir1/file.txt\n",
        "dir/subdir1/b.jpg\n",
        "dir/subdir2/random.txt\n",
        "dir/subdir3/test.png\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7CW89arnMSR"
      },
      "source": [
        "This is where data_root path currently is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GX55qQPnI7V"
      },
      "source": [
        "data_root"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWroCOjNXsCk"
      },
      "source": [
        "import random\n",
        "all_image_paths = list(data_root.glob('*/*'))\n",
        "all_image_paths = [str(path) for path in all_image_paths]\n",
        "random.shuffle(all_image_paths)\n",
        "all_image_paths[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z-rsfDUXVXS"
      },
      "source": [
        "# number of images\n",
        "image_count = len(all_image_paths)\n",
        "image_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zwqObLIXU0a"
      },
      "source": [
        "**That's only a list of paths to the files. How can I have a quick look so I know what I'm dealing with:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmREXoKOXwqG"
      },
      "source": [
        "import IPython.display as display\n",
        "\n",
        "for n in range(3):\n",
        "    image_path = random.choice(all_image_paths)\n",
        "    print(image_path)\n",
        "    display.display(display.Image(image_path))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdqsKBucYk9v"
      },
      "source": [
        "###Where/What are the labels?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhC0_fKdYs2m"
      },
      "source": [
        "*List the available labels:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IgkmoSuYPTE"
      },
      "source": [
        "for item in data_root.glob('*/'):\n",
        "  print(item, '-> Folder :',item.is_dir())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGU6XiqSYaDR"
      },
      "source": [
        "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "label_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuGHmlnvYx97"
      },
      "source": [
        "*Assign an index to each label:*\n",
        "\n",
        "label_to_index will be useful to assign each image to a index label based on its folder name!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmSQ_QE2YvcD"
      },
      "source": [
        "# short way\n",
        "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
        "label_to_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d2v40coYn-e"
      },
      "source": [
        "# long way\n",
        "label_to_index={}\n",
        "for index, name in enumerate(label_names):\n",
        "  label_to_index[name] = index\n",
        "\n",
        "label_to_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQjbNEf9s9CT"
      },
      "source": [
        "This index_to_label will be useful for prediction!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbuCogZDs4lG"
      },
      "source": [
        "index_to_label = {v: k for k, v in label_to_index.items()}\n",
        "index_to_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESuuEv1MY2rJ"
      },
      "source": [
        "*Create a list of label index:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ60ZzOnY8_9"
      },
      "source": [
        "# testing\n",
        "# get the first path\n",
        "one_path = all_image_paths[0]\n",
        "print(one_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFwNEJf9cKfS"
      },
      "source": [
        "# get the parent path\n",
        "pathlib.Path(one_path).parent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN5zbQyecV-a"
      },
      "source": [
        "# get the parent folder name\n",
        "parent_folder_name = pathlib.Path(one_path).parent.name\n",
        "print(parent_folder_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5mFUQMucbK_"
      },
      "source": [
        "# map the parent folder to index from our label_to_index dictionary\n",
        "label_to_index[parent_folder_name]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci8_p3DkYz_P"
      },
      "source": [
        "# all in one go\n",
        "all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                    for path in all_image_paths]\n",
        "\n",
        "print(\"First 10 labels indices: \", all_image_labels[:10])\n",
        "# print(\"First 10 paths: \")\n",
        "# all_image_paths[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBpX1bBrZUtx"
      },
      "source": [
        "**Cool, now how can I preprocess the images before training?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_E0ROW6Zfxj"
      },
      "source": [
        "*TensorFlow includes all the tools you need to load and process images. Here is the raw data:*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k73pVn-WY4kQ"
      },
      "source": [
        "img_path = all_image_paths[0]\n",
        "img_raw = tf.io.read_file(img_path)\n",
        "img_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjn-pAtGZq8n"
      },
      "source": [
        "*Decode it into an image tensor:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uQ_i8fPZr02"
      },
      "source": [
        "img_tensor = tf.image.decode_jpeg(img_raw, channels=3)\n",
        "\n",
        "print(img_tensor.shape)\n",
        "print(img_tensor.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slzgTnuleoYm"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3g7JF0pZwF7"
      },
      "source": [
        "*Resize it for your model:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af3V__WoZwoc"
      },
      "source": [
        "img_final = tf.image.resize(img_tensor, [192, 192])\n",
        "img_final = img_final/255.0\n",
        "print(img_final.shape)\n",
        "print(img_final.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skOhtcWQe7EL"
      },
      "source": [
        "plt.imshow(img_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXMPuHj4Z9I6"
      },
      "source": [
        "*Wrap up these up in a simple functions:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMsOfiLXZ4dI"
      },
      "source": [
        "def preprocess_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [192, 192])\n",
        "    image /= 255.0  # normalize to [0,1] range\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    image = tf.io.read_file(path)\n",
        "    return preprocess_image(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwpbTzX0aFE_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = all_image_paths[3101]\n",
        "label = all_image_labels[3101]\n",
        "\n",
        "plt.imshow(load_and_preprocess_image(image_path))\n",
        "plt.title(label_names[label])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVnlggR8fgN2"
      },
      "source": [
        "With our current dataset, it got 3670 images with each size 192x192x3 = 405,872,640 bytes = 400 MB or 0.4 GB which is fitted in our either RAM or GPU Memory. No problem!\n",
        "\n",
        "However, oftenly other image datasets are too large (10 million images with 1000x1000x3 size) to contains all the images in the memory :(( This is impossible for have the whole dataset stored in one go inside the memory!\n",
        "\n",
        "However, we can store a list of file paths in our RAM easily (only 3670 strings)\n",
        "\n",
        "So let's build an input pipeline for our ML model. A input pipeline takes in the raw data (our path), processes it (load, decode image, normalize it) and then feeds it to the model when the model requires for one mini-batch of data to train. \n",
        "\n",
        "So let's use **tf.data.Dataset** !\n",
        "\n",
        "![](https://i.pinimg.com/originals/b8/c4/04/b8c404b584f1804512bc19e7be91e222.gif)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRh__eV4oz3a"
      },
      "source": [
        "## Bulding pipeline with tf.data.dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdrnKa_Afn7F"
      },
      "source": [
        "*The easiest way is to build a `tf.data.Dataset`*\n",
        "\n",
        "The `tf.data.Dataset` API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n",
        "\n",
        "- Create a source dataset from your input data.\n",
        "- Apply dataset transformations to preprocess the data.\n",
        "- Iterate over the dataset and process the elements.\n",
        "Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory.\n",
        "\n",
        "More importantly, tf dataset will make the pipeline faster:\n",
        "\n",
        "**Without tf.dataset**\n",
        "\n",
        "![](https://miro.medium.com/max/2028/1*xJBrmPZm0LPDkQXt8WBXuQ.png)\n",
        "\n",
        "![](https://images.viblo.asia/606e25b5-bb38-444f-bddc-a45f4f7a2f34.png)\n",
        "\n",
        "**With tf.dataset**\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*TiZczQ0eSR6EX50xBeXnSg.png)\n",
        "\n",
        "\n",
        "![](https://images.viblo.asia/815bfa69-8363-48f4-bf7a-779d81c1a9d7.png)\n",
        "\n",
        "**The example of tf dataset pipeline**\n",
        "\n",
        "![](https://pic1.zhimg.com/80/v2-3b242922714b46837ac7a5ca55c63638_1440w.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ51xLDpzoia"
      },
      "source": [
        "### Examples with different methods of the tf.data.dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_fDACNJzubr"
      },
      "source": [
        "#### from_tensor_slices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st_WEot4z2an"
      },
      "source": [
        "Creates a Dataset whose elements are slices of the given tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXsqcXA4zwdC"
      },
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements.\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ui7JMsc0WwF"
      },
      "source": [
        "# Slicing a 2D tensor produces 1D tensor elements.\n",
        "dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpMSdg4D0faG"
      },
      "source": [
        "#### map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNwQHgPd0usr"
      },
      "source": [
        "Maps map_func across the elements of this dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MId-Eqp30qns"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "def add_one(ele):\n",
        "  return ele + 1\n",
        "dataset = dataset.map(add_one)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cecbMMlq1RBc"
      },
      "source": [
        "#### batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEgkzgtJ1Sds"
      },
      "source": [
        "Combines consecutive elements of this dataset into batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7zK9axR1Qbb"
      },
      "source": [
        "dataset = tf.data.Dataset.range(8)\n",
        "dataset = dataset.batch(3)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XaA6hID1l39"
      },
      "source": [
        "The components of the resulting element will have an additional outer dimension, which will be batch_size (or N % batch_size for the last element if batch_size does not divide the number of input elements N evenly and drop_remainder is False). If your program depends on the batches having the same outer dimension, you should set the drop_remainder argument to True to prevent the smaller batch from being produced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZToHUKF1fSY"
      },
      "source": [
        "dataset = tf.data.Dataset.range(8)\n",
        "dataset = dataset.batch(3, drop_remainder=True)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmFsEiZa1pqy"
      },
      "source": [
        "#### repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4wk7hr51tzw"
      },
      "source": [
        "Repeats this dataset so each original value is seen count times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sgpkLPs1uCL"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "dataset = dataset.repeat(3)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IntEV9g2Bke"
      },
      "source": [
        "#### shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hmhvAQG2C38"
      },
      "source": [
        "Randomly shuffles the elements of this dataset.\n",
        "\n",
        "This dataset fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.\n",
        "\n",
        "For instance, if your dataset contains 10,000 elements but buffer_size is set to 1,000, then shuffle will initially select a random element from only the first 1,000 elements in the buffer. Once an element is selected, its space in the buffer is replaced by the next (i.e. 1,001-st) element, maintaining the 1,000 element buffer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xR0IXZX1__7"
      },
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
        "print(list(dataset.as_numpy_iterator()))\n",
        "print(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQW2L4js2YLB"
      },
      "source": [
        "reshuffle_each_iteration controls whether the shuffle order should be different for each epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnAVen662PMZ"
      },
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
        "print(list(dataset.as_numpy_iterator()))\n",
        "print(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnyiMjln4GVP"
      },
      "source": [
        "### shuffle and repeat order, shuffle buffer size, reshuffle_each_iteration best practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PMCicDq4OjC"
      },
      "source": [
        "Spot the difference?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s1ZeNV45UE-"
      },
      "source": [
        "full buffer size, shuffle then repeat, reshuffle_each_iteration=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCiV4AC832WH"
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "dataset = dataset.shuffle(5, reshuffle_each_iteration=True)\n",
        "dataset = dataset.repeat(3)\n",
        "print(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JoJJ5V55cEo"
      },
      "source": [
        "full buffer size, shuffle then repeat, reshuffle_each_iteration=False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVVB2UHT4Bdb"
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "dataset = dataset.shuffle(5, reshuffle_each_iteration=False)\n",
        "dataset = dataset.repeat(3)\n",
        "print(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIe9FLQh5g6M"
      },
      "source": [
        "full buffer size, repeat then shuffle, reshuffle_each_iteration=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1UwcBJN4Slb"
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "dataset = dataset.repeat(3)\n",
        "dataset = dataset.shuffle(5, reshuffle_each_iteration=True)\n",
        "print(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xo283Pt5oxE"
      },
      "source": [
        "full buffer size, repeat then shuffle, reshuffle_each_iteration=False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5Nbpz204XDt"
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "dataset = dataset.repeat(3)\n",
        "dataset = dataset.shuffle(5, reshuffle_each_iteration=False)\n",
        "print(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEaJPF5k6tpr"
      },
      "source": [
        "small buffer size, shuffle then repeat, reshuffle_each_iteration=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rxOE4eh6qOp"
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "dataset = dataset.shuffle(2, reshuffle_each_iteration=True)\n",
        "dataset = dataset.repeat(3)\n",
        "print(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3QZnHQH5tFd"
      },
      "source": [
        "small buffer size, shuffle then repeat, reshuffle_each_iteration=False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDkIfWpy5G1D"
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "dataset = dataset.shuffle(2, reshuffle_each_iteration=False)\n",
        "dataset = dataset.repeat(3)\n",
        "print(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5HyYwOJ5wQG"
      },
      "source": [
        "small buffer size, repeat then shuffle, reshuffle_each_iteration=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsXG9W4A5KSo"
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "dataset = dataset.repeat(3)\n",
        "dataset = dataset.shuffle(2, reshuffle_each_iteration=True)\n",
        "print(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQjLLWeh52LS"
      },
      "source": [
        "small buffer size, repeat then shuffle, reshuffle_each_iteration=False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJeLT11s5NgQ"
      },
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "dataset = dataset.repeat(3)\n",
        "dataset = dataset.shuffle(2, reshuffle_each_iteration=False)\n",
        "print(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AtF13KR2h2h"
      },
      "source": [
        "#### skip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIrjOHFQ2lEB"
      },
      "source": [
        "Creates a Dataset that skips count elements from this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7r1qnv_2j0w"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.skip(7)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlZ9IBb92q7K"
      },
      "source": [
        "#### take"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDmMqKsa2sve"
      },
      "source": [
        "Creates a Dataset with at most count elements from this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi_u7pRb2o2G"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.take(3)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRrIvcjh3XNL"
      },
      "source": [
        "### Use tf.data.dataset to build the pipeline in flower dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fjpb4KqaKzn"
      },
      "source": [
        "# Testing: Slicing the array of strings, results in a dataset of strings (convert to tensor type for tf.dataset)\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDd0PxhxiZdA"
      },
      "source": [
        "path_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC0ueRzwhpGP"
      },
      "source": [
        "*Now create a new dataset that loads and formats images on the fly by mapping `load_preprocess_image` over the dataset of paths.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQDw42Ydf4is"
      },
      "source": [
        "# This is where the pipeline starts\n",
        "ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n",
        "\n",
        "# The tuples are unpacked into the positional arguments of the mapped function\n",
        "def load_and_preprocess_from_path_label(path, label):\n",
        "  return load_and_preprocess_image(path), label\n",
        "\n",
        "ds_map = ds.map(load_and_preprocess_from_path_label)\n",
        "\n",
        "# add cache to increase the speed\n",
        "ds_map_cache = ds.map(load_and_preprocess_from_path_label).cache()\n",
        "ds_map_cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAdbmsxjjPWo"
      },
      "source": [
        "*To train a model with this dataset, you will want the data:*\n",
        "* *To be well shuffeled*\n",
        "* *To be batched*\n",
        "* *To repeat forever*\n",
        "* *Batches to be available as soon as possible*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvYGeOyXvuiC"
      },
      "source": [
        "# Let trainset is 70%, validation is 30%\n",
        "train_size = int(0.7 * image_count)\n",
        "val_size = int(0.3 * image_count)\n",
        "\n",
        "# shuffle time, since the number of image paths this time is not too large so we can shuffle the whole list\n",
        "# Setting a shuffle buffer size as large as the dataset ensures that the data is completely shuffled.\n",
        "#ds_map_cache = ds_map_cache.shuffle(buffer_size = image_count)\n",
        "\n",
        "# Split into train and test set\n",
        "train_dataset = ds_map_cache.take(train_size)\n",
        "test_dataset = ds_map_cache.skip(train_size)\n",
        "\n",
        "\n",
        "# Mini-batch\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# add autotune means asking tensorflow to figure out the best settings for your VM/laptop running\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# `repeat` will allows the dataset to be repeat forever\n",
        "# `prefetch` lets the dataset fetch batches in the background with CPU while the model is training on GPU.\n",
        "SHUFFLE_BUFFER_SIZE= 1024\n",
        "final_train_dataset = train_dataset.repeat().shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "final_test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cClc6gfEguD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8vPMKeTml-z"
      },
      "source": [
        "> There are a few things to note here:\n",
        "\n",
        "> The order is important.\n",
        "\n",
        "> * A .shuffle after a .repeat would shuffle items across epoch boundaries (some items will be seen twice before others are seen at all).\n",
        "\n",
        "> * A .shuffle after a .batch would shuffle the order of the batches, but not shuffle the items across batches.\n",
        "\n",
        "> * You use a buffer_size the same size as the dataset for a full shuffle. Up to the dataset size, large values provide better randomization, but use more memory.\n",
        "\n",
        "> * The shuffle buffer is filled before any elements are pulled from it. So a large buffer_size may cause a delay when your Dataset is starting.\n",
        "\n",
        "> * The shuffeled dataset doesn't report the end of a dataset until the shuffle-buffer is completely empty. The Dataset is restarted by .repeat, causing another wait for the shuffle-buffer to be filled.\n",
        "\n",
        "Utimately, here is the order you should try to follow:\n",
        "\n",
        "For train dataset -> Map -> Cache -> Repeat -> Shuffle -> Batch -> Prefetch\n",
        "\n",
        "For test dataset -> Map -> Cache (optional) -> Batch -> Prefetch (optional)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnSQWu-6q_u_"
      },
      "source": [
        "**Awesome! Finally, now we need a model right!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkIF2v1nrQ3G"
      },
      "source": [
        "\n",
        "#Transfer Learning\n",
        "\n",
        "Let's cheat by using transfer learning to give our model a big boost without putting effort to train or tune our model! \n",
        "\n",
        "It is a popular approach in deep learning where pre-trained models are used as the starting point on computer vision and natural language processing tasks given the vast compute and time resources required to develop neural network models on these problems and from the huge jumps in skill that they provide on related problems.\n",
        "\n",
        "*It's fine, eveything is new on the first day. And you will see that I'm very \"user-friendly\".*\n",
        "\n",
        "![](https://miro.medium.com/max/441/1*TIMA09tVqZe7tA6DckoP6g.png)\n",
        "\n",
        "![](https://cdn-media-1.freecodecamp.org/images/nhxsEn9S-VwNdFKCClwfeKhKmTd1buwzF3pR)\n",
        "\n",
        "------------------------------------------\n",
        "\n",
        "![](https://www.mathworks.com/discovery/transfer-learning/_jcr_content/mainParsys/image.adapt.full.high.jpg/1576731630627.jpg)\n",
        "\n",
        "---------------------------------------------\n",
        "\n",
        "![](https://i.stack.imgur.com/d0iwP.png)\n",
        "\n",
        "--------------------------------------------------\n",
        "\n",
        "![](https://www.learnopencv.com/wp-content/uploads/2019/06/Model_Timeline.png)\n",
        "\n",
        "*Okay we've learned how to build a model. Let's jump a big step ahead and I'll show you a simple transfer learning example:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux6nHejZxjFC"
      },
      "source": [
        "*Fetch a copy of MobileNet v2 from [tf.keras.applications](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/applications)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22wlDBO9iUwk"
      },
      "source": [
        "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3), include_top=False)\n",
        "mobile_net.trainable=False  # freeze all the layers of the pre-trained model so their weights and bias won't be updated during gradient descent steps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN2A9eC0yql0"
      },
      "source": [
        "*Build a model wrapped around MobileNet and use [tf.keras.layers.GlobalAveragePooling2D](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) to average over those space dimensions before the output tf.keras.layers.Dense layer:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZMEB3MtQZIJ"
      },
      "source": [
        "len(mobile_net.layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6K-i5NvQm7G"
      },
      "source": [
        "mobile_net.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r6vHKTHQIoO"
      },
      "source": [
        "for i in mobile_net.layers:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0t734QRxibA"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    mobile_net,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(len(label_names), activation = 'softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsn9Chm64sFY"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfxkjONKyhky"
      },
      "source": [
        "*Compile the model to describe the training procedure:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBTGh4MCyiKg"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkoXjjeoy3Wr"
      },
      "source": [
        "steps_per_epoch=tf.math.ceil(len(all_image_paths)/BATCH_SIZE).numpy()\n",
        "history = model.fit(final_train_dataset,validation_data=final_test_dataset, epochs=10, steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnnixUstPKHn"
      },
      "source": [
        "model.save('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZMxPrCOtv9U"
      },
      "source": [
        "The prediction time!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq27i4bPsKY7",
        "outputId": "196c68b7-6c9e-410d-8c7f-8e9ac9eb4f00",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print(fn)\n",
        "  path = '/content/' + fn\n",
        "  flower = load_and_preprocess_image(path)\n",
        "\n",
        "  # reshape it to match with the trained images\n",
        "  reshaped_flower = tf.reshape(flower, [1,192,192,3])\n",
        "\n",
        "  # forward propagation :))\n",
        "  prediction = model.predict(reshaped_flower)\n",
        "\n",
        "  # get the index for the highest probability\n",
        "  label_index = tf.math.argmax(prediction[0])\n",
        "\n",
        "  # select the label from the index\n",
        "  print(\"The prediction is\", index_to_label[label_index.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26603b86-8b9d-46f1-ae33-ab9064bc1d93\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-26603b86-8b9d-46f1-ae33-ab9064bc1d93\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER8Q7f3sJUr-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}