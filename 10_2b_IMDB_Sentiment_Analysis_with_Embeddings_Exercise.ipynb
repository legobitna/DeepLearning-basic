{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 10.2b_IMDB_Sentiment_Analysis_with_Embeddings_Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/legobitna/DeepLearning-basic/blob/main/10_2b_IMDB_Sentiment_Analysis_with_Embeddings_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XERofKqiRqKv"
      },
      "source": [
        "# IMBD Sentiment Analysis with different model architectures and Glove Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vShQG2qvRz3q"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1rjXBbYBkkF"
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EZwVpzrB4NB"
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 100\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZInTeqTZ0FG"
      },
      "source": [
        "Let's import tensorflow datasets library and download IDMB text reviews dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS0HtPssB5Eo",
        "outputId": "92795226-64d4-4b79-8993-dd9367ca5be8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n",
        "print(\"dd\",imdb)\n",
        "print(\"cc\",info)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dd {'test': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>, 'train': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>, 'unsupervised': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>}\n",
            "cc tfds.core.DatasetInfo(\n",
            "    name='imdb_reviews',\n",
            "    version=1.0.0,\n",
            "    description='Large Movie Review Dataset.\n",
            "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
            "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
            "    features=FeaturesDict({\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "        'text': Text(shape=(), dtype=tf.string),\n",
            "    }),\n",
            "    total_num_examples=100000,\n",
            "    splits={\n",
            "        'test': 25000,\n",
            "        'train': 25000,\n",
            "        'unsupervised': 50000,\n",
            "    },\n",
            "    supervised_keys=('text', 'label'),\n",
            "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
            "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
            "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
            "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
            "      month     = {June},\n",
            "      year      = {2011},\n",
            "      address   = {Portland, Oregon, USA},\n",
            "      publisher = {Association for Computational Linguistics},\n",
            "      pages     = {142--150},\n",
            "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jd1uFlZCIqv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data, test_data = imdb['train'], imdb['test']\n",
        "\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []\n",
        "\n",
        "# str(s.tonumpy()) is needed in Python3 instead of just s.numpy()\n",
        "for s,l in train_data:\n",
        "  training_sentences.append(s.numpy().decode('utf8'))\n",
        "  training_labels.append(l.numpy())\n",
        "  \n",
        "for s,l in test_data:\n",
        "  testing_sentences.append(s.numpy().decode('utf8'))\n",
        "  testing_labels.append(l.numpy())\n",
        "  \n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euub4rPAayrj",
        "outputId": "9ce98b06-7b33-4dac-d093-1189587b11bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Sentence:\", training_sentences[0])\n",
        "print(\"Label:\", training_labels[0])\n",
        "print(\"---------------------------------\")\n",
        "print(\"Sentence:\", training_sentences[1])\n",
        "print(\"Label:\", training_labels[1])\n",
        "print(\"---------------------------------\")\n",
        "print(\"Sentence:\", training_sentences[3])\n",
        "print(\"Label:\", training_labels[3])\n",
        "print(\"---------------------------------\")\n",
        "print(\"Sentence:\", training_sentences[5])\n",
        "print(\"Label:\", training_labels[5])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\n",
            "Label: 0\n",
            "---------------------------------\n",
            "Sentence: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.\n",
            "Label: 0\n",
            "---------------------------------\n",
            "Sentence: This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.\n",
            "Label: 1\n",
            "---------------------------------\n",
            "Sentence: This is a film which should be seen by anybody interested in, effected by, or suffering from an eating disorder. It is an amazingly accurate and sensitive portrayal of bulimia in a teenage girl, its causes and its symptoms. The girl is played by one of the most brilliant young actresses working in cinema today, Alison Lohman, who was later so spectacular in 'Where the Truth Lies'. I would recommend that this film be shown in all schools, as you will never see a better on this subject. Alison Lohman is absolutely outstanding, and one marvels at her ability to convey the anguish of a girl suffering from this compulsive disorder. If barometers tell us the air pressure, Alison Lohman tells us the emotional pressure with the same degree of accuracy. Her emotional range is so precise, each scene could be measured microscopically for its gradations of trauma, on a scale of rising hysteria and desperation which reaches unbearable intensity. Mare Winningham is the perfect choice to play her mother, and does so with immense sympathy and a range of emotions just as finely tuned as Lohman's. Together, they make a pair of sensitive emotional oscillators vibrating in resonance with one another. This film is really an astonishing achievement, and director Katt Shea should be proud of it. The only reason for not seeing it is if you are not interested in people. But even if you like nature films best, this is after all animal behaviour at the sharp edge. Bulimia is an extreme version of how a tormented soul can destroy her own body in a frenzy of despair. And if we don't sympathise with people suffering from the depths of despair, then we are dead inside.\n",
            "Label: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoIZ9_rsbGlT"
      },
      "source": [
        "Time to tokenize our sentences and pad them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzePDzHBCJ4b"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPcmXDrTCKw7",
        "outputId": "71ebbd73-53b4-420c-964a-cf971239f71f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "print(\"Original:\", training_sentences[0])\n",
        "print(\"Tokenize:\", sequences[0])\n",
        "print(\"Reduce or Padded:\", padded[0])\n",
        "print(\"Decode:\", decode_review(padded[0]))\n",
        "print(\"Label:\", training_labels_final[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\n",
            "Tokenize: [12, 14, 33, 425, 392, 18, 90, 28, 1, 9, 32, 1366, 3585, 40, 486, 1, 197, 24, 85, 154, 19, 12, 213, 329, 28, 66, 247, 215, 9, 477, 58, 66, 85, 114, 98, 22, 5675, 12, 1322, 643, 767, 12, 18, 7, 33, 400, 8170, 176, 2455, 416, 2, 89, 1231, 137, 69, 146, 52, 2, 1, 7577, 69, 229, 66, 2933, 16, 1, 2904, 1, 1, 1479, 4940, 3, 39, 3900, 117, 1584, 17, 3585, 14, 162, 19, 4, 1231, 917, 7917, 9, 4, 18, 13, 14, 4139, 5, 99, 145, 1214, 11, 242, 683, 13, 48, 24, 100, 38, 12, 7181, 5515, 38, 1366, 1, 50, 401, 11, 98, 1197, 867, 141, 10]\n",
            "Reduce or Padded: [  12   14   33  425  392   18   90   28    1    9   32 1366 3585   40\n",
            "  486    1  197   24   85  154   19   12  213  329   28   66  247  215\n",
            "    9  477   58   66   85  114   98   22 5675   12 1322  643  767   12\n",
            "   18    7   33  400 8170  176 2455  416    2   89 1231  137   69  146\n",
            "   52    2    1 7577   69  229   66 2933   16    1 2904    1    1 1479\n",
            " 4940    3   39 3900  117 1584   17 3585   14  162   19    4 1231  917\n",
            " 7917    9    4   18   13   14 4139    5   99  145 1214   11  242  683\n",
            "   13   48]\n",
            "Decode: this was an absolutely terrible movie don't be <OOV> in by christopher walken or michael <OOV> both are great actors but this must simply be their worst role in history even their great acting could not redeem this movie's ridiculous storyline this movie is an early nineties us propaganda piece the most pathetic scenes were those when the <OOV> rebels were making their cases for <OOV> maria <OOV> <OOV> appeared phony and her pseudo love affair with walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning i am disappointed that there\n",
            "Label: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afnHHEkBcfFT"
      },
      "source": [
        "It's always good to visualize training and validation loss or accuracy after training the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgHzLvKaWnI-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHqtvkdKR4FI"
      },
      "source": [
        "## Embedding layer with Flatten Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y13BoZ4mCLj8",
        "outputId": "c45e9c60-57d0-45c9-f31c-285994765ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# YOUR CODE\n",
        "# Build model with Flatten(), a Fully Connected Layer like 8 neurons and the last layer is a Fully Connected Layer with 1 neuron with activation is 'sigmoid'\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    # your code\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "    \n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 80008     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 1,080,017\n",
            "Trainable params: 1,080,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EJAosxWCMjT",
        "outputId": "915d2fbd-6fa4-4e41-f9ed-acae550cbdfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_epochs = 10\n",
        "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4741 - accuracy: 0.7616 - val_loss: 0.3753 - val_accuracy: 0.8320\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1341 - accuracy: 0.9570 - val_loss: 0.4738 - val_accuracy: 0.8056\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 0.5486 - val_accuracy: 0.8147\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5911 - val_accuracy: 0.8190\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 5.4652e-04 - accuracy: 1.0000 - val_loss: 0.6214 - val_accuracy: 0.8216\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 2.8994e-04 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.8228\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 1.6808e-04 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8225\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.0074e-04 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8237\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 6.2365e-05 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.8241\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 3.8679e-05 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.8241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPUac50sWpnr",
        "outputId": "b136b99d-ee01-4646-c86e-9c8f4d572dba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AP_Z6-dRn3o"
      },
      "source": [
        "### Prediction sentiment of some sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeffQj92Rmg1",
        "outputId": "41684e39-6fba-4b38-be59-73b5192c943d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# YOUR CODE\n",
        "# Hopefully, the first and third sentences are positive and middle one is negative\n",
        "\n",
        "sentence = [\"I really think this is amazing. honest.\", \"It sucks and so bad\", \"I love it so much!\"]\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "print(\"Sequences:\", sequences)\n",
        "padded =  pad_sequences(sequences, padding=padding_type,maxlen=max_length)\n",
        "print(\"Padded:\", padded)\n",
        "print(\"Prediction:\", model.predict(padded))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequences: [[11, 64, 102, 12, 7, 478, 1199], [10, 1862, 3, 36, 76], [11, 117, 10, 36, 74]]\n",
            "Padded: [[  11   64  102   12    7  478 1199    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [  10 1862    3   36   76    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [  11  117   10   36   74    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Prediction: [[0.85586554]\n",
            " [0.00466713]\n",
            " [0.06369615]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCO-BVVUUQnT"
      },
      "source": [
        "### Export the Embedding layer into vecs and meta files to visualise "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mMm61sGUoJC"
      },
      "source": [
        "Run this code to export the values of vectors in embedding (vecs.tsv) and coressponding words (meta.tsv). Thus, you will have two files in total.\n",
        "\n",
        "Remember to click \"Allow to download multiple files\" on Chrome to download two files at the same time!\n",
        "\n",
        "Open http://projector.tensorflow.org/ and load those two files you just download so see the visualization in 3D or 2D of your word embedding!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG_tL2cfVGuf"
      },
      "source": [
        "import io\n",
        "def export_embedding_tsv(model):\n",
        "  e = model.layers[0]\n",
        "  weights = e.get_weights()[0]\n",
        "  #print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
        "\n",
        "  out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "  out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "  for word_num in range(1, vocab_size):\n",
        "    word = reverse_word_index[word_num]\n",
        "    embeddings = weights[word_num]\n",
        "    out_m.write(word + \"\\n\")\n",
        "    out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "  out_v.close()\n",
        "  out_m.close()\n",
        "\n",
        "  try:\n",
        "    from google.colab import files\n",
        "  except ImportError:\n",
        "    pass\n",
        "  else:\n",
        "    files.download('vecs.tsv')\n",
        "    files.download('meta.tsv')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THNtCHZDVc7D",
        "outputId": "f1b41e38-329d-4a02-a9d5-a9944d830fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "export_embedding_tsv(model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b4ed97a9-f1c5-4611-a731-585457243582\", \"vecs.tsv\", 12154257)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_92af5779-8ebe-4f27-96dd-85dc3e4d502f\", \"meta.tsv\", 76186)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA7YtjslR9Z_"
      },
      "source": [
        "## Embedding layer with Global Average Pooling Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su5KdtXEWESa",
        "outputId": "b690c066-98da-4ce4-ab7c-14e57ce6ee3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# YOUR CODE\n",
        "# Use Global Average Pooling 1D and 2 Dense Layers with the last layer is one neuron and activation is sigmoid. \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    # your code\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "\n",
        "    \n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 808       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 1,000,817\n",
            "Trainable params: 1,000,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbEcz-Y2WWTv",
        "outputId": "22c249a3-192c-45ed-8546-56a46c3d0286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "num_epochs = 10\n",
        "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-52dc59d2e6f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 25000\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhnD_eqTWq22"
      },
      "source": [
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f75qGSBhS3N"
      },
      "source": [
        "Do you notice anything different from the last model about speed and accuracy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTVvOdj8SICd"
      },
      "source": [
        "## Embedding layer with a LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY90QbBgSMKC",
        "outputId": "9a599cbd-4f17-47e8-9b66-c924ff36aa5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# YOUR CODE\n",
        "# Use LSTM layer with 2 Dense Layers followed it\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    # your code\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(8,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid'),\n",
        "    \n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 520       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 1,042,769\n",
            "Trainable params: 1,042,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWlImbp_SPDW",
        "outputId": "b78954b5-037d-4b56-ea13-025b461a8bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "num_epochs = 10\n",
        "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-52dc59d2e6f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 25000\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsPYMPgnSQZV"
      },
      "source": [
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuBLVtOCZ25F"
      },
      "source": [
        "## Embedding layer with a Bidirectional LSTM layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tk6yN6bZ8ht",
        "outputId": "413d6b94-50d9-4732-b49c-ab4736814356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# YOUR CODE\n",
        "# Use bidirectional LSTM with 2 dense layers\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    # your code\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(8,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid'),\n",
        "    \n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               84480     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 8)                 1032      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 1,085,521\n",
            "Trainable params: 1,085,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZSjpBVwaZOU",
        "outputId": "3516f5cc-90d5-4552-e45e-fa7e0c142319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "num_epochs = 10\n",
        "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-52dc59d2e6f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 25000\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MamEz8hKaeE6"
      },
      "source": [
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7rTkvXlawmw"
      },
      "source": [
        "## Embedding layer with multiple Bidirectional LSTM layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XANJ8jNNbJpN",
        "outputId": "31ac31f4-eb19-4553-8407-e9ddac454ec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# YOUR CODE\n",
        "# Use stacked bidirectional LSTM (2 bidirectional LSTM stacked on each other) with two dense layers \n",
        "# be mindful about return_sequence \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    # your code\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(8,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid'),\n",
        "\n",
        "    \n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "num_epochs = 10\n",
        "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))\n",
        "\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 100, 128)          84480     \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 8)                 520       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 1,126,225\n",
            "Trainable params: 1,126,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-080d91afaf8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 25000\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB6sAK56bW3e"
      },
      "source": [
        "## CNN 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swElQgzxbZvE",
        "outputId": "db73714a-1cc3-4447-b190-1345d131d56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "num_epochs = 10\n",
        "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))\n",
        "\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,072,449\n",
            "Trainable params: 1,072,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-81b05a9600b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 25000\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N07CN2Kh8Gn"
      },
      "source": [
        "What do you think about this model compared to other models? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo-23xZTh8Ez"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKw1yOdOb_qk"
      },
      "source": [
        "## Load Pre-trained Glove Embeddings into the Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnFC4ZTwPVVA"
      },
      "source": [
        "word_index_size = len(word_index)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29xYX5P8cDUB",
        "outputId": "d8f0b27f-315f-42fe-fc60-23f81b9d7497",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Note this is the 100 dimension version of GloVe from Stanford\n",
        "# I unzipped and hosted it on my site to make this notebook easier\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n",
        "    -O /tmp/glove.6B.100d.txt\n",
        "embeddings_index = {};\n",
        "with open('/tmp/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split();\n",
        "        word = values[0];\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\n",
        "        embeddings_index[word] = coefs;\n",
        "\n",
        "embeddings_matrix = np.zeros((word_index_size+1, embedding_dim));\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word);\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector;"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-12 17:15:53--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 74.125.142.128, 172.253.117.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘/tmp/glove.6B.100d.txt’\n",
            "\n",
            "/tmp/glove.6B.100d. 100%[===================>] 331.04M   153MB/s    in 2.2s    \n",
            "\n",
            "2020-11-12 17:15:55 (153 MB/s) - ‘/tmp/glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2xH6vzWcEyu",
        "outputId": "d2817dcf-76a8-46f3-d18e-754b50080648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(embeddings_matrix))\n",
        "# Expected Output\n",
        "# 88584"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yZhLHn3TkOm",
        "outputId": "bddf32c7-a7a7-4c7c-9bca-a46e4ed0c251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(word_index_size+1, embedding_dim, input_length=max_length, weights=[embeddings_matrix], trainable=False),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "num_epochs = 10\n",
        "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))\n",
        "\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 100, 100)          8858400   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 8,930,849\n",
            "Trainable params: 72,449\n",
            "Non-trainable params: 8,858,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-9b356f855717>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 25000\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UdTd_2QTxB9"
      },
      "source": [
        "Trying another architecture with Dropout and MaxPooling1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q7CozZzcImD",
        "outputId": "12351cc5-427c-4364-d0f3-3b571433f411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(word_index_size+1, embedding_dim, input_length=max_length, weights=[embeddings_matrix], trainable=False),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "num_epochs = 10\n",
        "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))\n",
        "\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 100, 100)          8858400   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 96, 64)            32064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 8,923,553\n",
            "Trainable params: 65,153\n",
            "Non-trainable params: 8,858,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-03e48ba6aaed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 25000\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiy-eZ66UF-v"
      },
      "source": [
        "After using dropout layer, the gap between training and validation is more narrow which is a good sign of reducing overfitting!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzDbdF-fWdSC"
      },
      "source": [
        "Also, we can try to export the tsv files from Embedding to visual it. Remember this is the Glove pre-trained embedding so it's not specialised for sentiment analysis so you can really see positive words (like good) on one side and negative words (like bad) on the other side like how we train our embedding layer from scratch.\n",
        "\n",
        "Glove embedding is more powerful and general which is suitable for more tasks like predicting the next word in the sentences,..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3_BIEjaV4xV",
        "outputId": "c7b1d620-90a8-468b-bbbc-e5cedb8ac25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "export_embedding_tsv(model)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a3ce9422-4691-46ef-8465-3690dda5570d\", \"vecs.tsv\", 8427752)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_96a74ab8-fa54-4018-8337-5cb83a4d2daf\", \"meta.tsv\", 76186)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "185CMG9eXGWL"
      },
      "source": [
        "I hope you guys have fun and learn how to design many different architectures. Once again, you can see that sometimes data is more important than different architectures since most of the models performance slightly differently for this toy IMBD dataset."
      ]
    }
  ]
}